{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e328e1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Libraries loaded.\n",
      "\n",
      "Sentiment dataset preview:\n",
      "    timestamp  value classification        date\n",
      "0  1517463000     30           Fear  2018-02-01\n",
      "1  1517549400     15   Extreme Fear  2018-02-02\n",
      "2  1517635800     40           Fear  2018-02-03\n",
      "\n",
      "Trades dataset preview:\n",
      "                                      account  coin  execution price  \\\n",
      "0  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9769   \n",
      "1  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9800   \n",
      "2  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9855   \n",
      "\n",
      "   size tokens  size usd side     timestamp ist  start position direction  \\\n",
      "0       986.87   7872.16  BUY  02-12-2024 22:50        0.000000       Buy   \n",
      "1        16.00    127.68  BUY  02-12-2024 22:50      986.524596       Buy   \n",
      "2       144.09   1150.63  BUY  02-12-2024 22:50     1002.518996       Buy   \n",
      "\n",
      "   closed pnl                                   transaction hash     order id  \\\n",
      "0         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
      "1         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
      "2         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
      "\n",
      "   crossed       fee      trade id     timestamp  \n",
      "0     True  0.345404  8.950000e+14  1.730000e+12  \n",
      "1     True  0.005600  4.430000e+14  1.730000e+12  \n",
      "2     True  0.050431  6.600000e+14  1.730000e+12  \n",
      "\n",
      "Merged dataset shape: (0, 18)\n",
      "Empty DataFrame\n",
      "Columns: [date, Classification]\n",
      "Index: []\n",
      "\n",
      "Missing values:\n",
      "account             0\n",
      "coin                0\n",
      "execution price     0\n",
      "size tokens         0\n",
      "size usd            0\n",
      "side                0\n",
      "timestamp ist       0\n",
      "start position      0\n",
      "direction           0\n",
      "closed pnl          0\n",
      "transaction hash    0\n",
      "order id            0\n",
      "crossed             0\n",
      "fee                 0\n",
      "trade id            0\n",
      "timestamp           0\n",
      "date                0\n",
      "Classification      0\n",
      "dtype: int64\n",
      "\n",
      "Columns available:\n",
      "['account', 'coin', 'execution price', 'size tokens', 'size usd', 'side', 'timestamp ist', 'start position', 'direction', 'closed pnl', 'transaction hash', 'order id', 'crossed', 'fee', 'trade id', 'timestamp', 'date', 'Classification']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Label(s) ['leverage', 'size'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 114\u001b[39m\n\u001b[32m    106\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mwin\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mclosedPnL\u001b[39m\u001b[33m\"\u001b[39m] > \u001b[32m0\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# 6. DAILY TRADER METRICS\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[32m    112\u001b[39m daily = (\n\u001b[32m    113\u001b[39m     \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maccount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mClassification\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdaily_PnL\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclosedPnL\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_trades\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclosedPnL\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43mavg_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[43mavg_leverage\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mleverage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlong_trades\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mside\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbuy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshort_trades\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mside\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwin_days\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m     .reset_index()\n\u001b[32m    125\u001b[39m )\n\u001b[32m    127\u001b[39m daily[\u001b[33m\"\u001b[39m\u001b[33mlong_ratio\u001b[39m\u001b[33m\"\u001b[39m] = daily[\u001b[33m\"\u001b[39m\u001b[33mlong_trades\u001b[39m\u001b[33m\"\u001b[39m] / daily[\u001b[33m\"\u001b[39m\u001b[33mshort_trades\u001b[39m\u001b[33m\"\u001b[39m].replace(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m    129\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDaily metrics:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\groupby\\generic.py:2291\u001b[39m, in \u001b[36mDataFrameGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   2288\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m   2290\u001b[39m op = GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args=args, kwargs=kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m2291\u001b[39m result = \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2293\u001b[39m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[32m   2294\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.as_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\apply.py:294\u001b[39m, in \u001b[36mApply.agg\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_str()\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[32m    296\u001b[39m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[32m    297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_list_like()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\apply.py:511\u001b[39m, in \u001b[36mApply.agg_dict_like\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame | Series:\n\u001b[32m    504\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[33;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[32m    506\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    509\u001b[39m \u001b[33;03m    Result of aggregation.\u001b[39;00m\n\u001b[32m    510\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\apply.py:1677\u001b[39m, in \u001b[36mGroupByApply.agg_or_apply_dict_like\u001b[39m\u001b[34m(self, op_name)\u001b[39m\n\u001b[32m   1672\u001b[39m     kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m: engine, \u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m: engine_kwargs})\n\u001b[32m   1674\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m com.temp_setattr(\n\u001b[32m   1675\u001b[39m     obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition=\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1676\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1677\u001b[39m     result_index, result_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1680\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[32m   1681\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\apply.py:550\u001b[39m, in \u001b[36mApply.compute_dict_like\u001b[39m\u001b[34m(self, op_name, selected_obj, selection, kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m is_groupby = \u001b[38;5;28misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[32m    549\u001b[39m func = cast(AggFuncTypeDict, \u001b[38;5;28mself\u001b[39m.func)\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m func = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalize_dictlike_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    552\u001b[39m is_non_unique_col = (\n\u001b[32m    553\u001b[39m     selected_obj.ndim == \u001b[32m2\u001b[39m\n\u001b[32m    554\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m selected_obj.columns.nunique() < \u001b[38;5;28mlen\u001b[39m(selected_obj.columns)\n\u001b[32m    555\u001b[39m )\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m selected_obj.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    558\u001b[39m     \u001b[38;5;66;03m# key only used for output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\apply.py:762\u001b[39m, in \u001b[36mApply.normalize_dictlike_arg\u001b[39m\u001b[34m(self, how, obj, func)\u001b[39m\n\u001b[32m    759\u001b[39m     cols = Index(\u001b[38;5;28mlist\u001b[39m(func.keys())).difference(obj.columns, sort=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) > \u001b[32m0\u001b[39m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;66;03m# GH 58474\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLabel(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m do not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    764\u001b[39m aggregator_types = (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    766\u001b[39m \u001b[38;5;66;03m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[32m    767\u001b[39m \u001b[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[32m    768\u001b[39m \u001b[38;5;66;03m# be list-likes\u001b[39;00m\n\u001b[32m    769\u001b[39m \u001b[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: \"Label(s) ['leverage', 'size'] do not exist\""
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 1. INSTALL + IMPORT LIBRARIES\n",
    "# ==============================\n",
    "%pip install scikit-learn -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "print(\"Libraries loaded.\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 2. LOAD DATA\n",
    "# ==============================\n",
    "sentiment = pd.read_csv(\"../data/fear_greed_index.csv\")\n",
    "trades = pd.read_csv(\"../data/historical_data.csv\")\n",
    "\n",
    "# Standardize column names\n",
    "sentiment.columns = sentiment.columns.str.strip().str.lower()\n",
    "trades.columns = trades.columns.str.strip().str.lower()\n",
    "\n",
    "print(\"\\nSentiment dataset preview:\")\n",
    "print(sentiment.head(3))\n",
    "\n",
    "print(\"\\nTrades dataset preview:\")\n",
    "print(trades.head(3))\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3. DATE CLEANING\n",
    "# ==============================\n",
    "\n",
    "# ---- SENTIMENT DATE ----\n",
    "if \"timestamp ist\" in sentiment.columns:\n",
    "    sentiment[\"date\"] = pd.to_datetime(sentiment[\"timestamp ist\"], errors=\"coerce\")\n",
    "elif \"timestamp\" in sentiment.columns:\n",
    "    sentiment[\"date\"] = pd.to_datetime(sentiment[\"timestamp\"], errors=\"coerce\")\n",
    "elif \"date\" in sentiment.columns:\n",
    "    sentiment[\"date\"] = pd.to_datetime(sentiment[\"date\"], errors=\"coerce\")\n",
    "else:\n",
    "    raise KeyError(\"Sentiment dataset missing date column\")\n",
    "\n",
    "# Classification column\n",
    "if \"classification\" not in sentiment.columns:\n",
    "    raise KeyError(\"Sentiment dataset must contain 'classification' column\")\n",
    "\n",
    "sentiment.rename(columns={\"classification\": \"Classification\"}, inplace=True)\n",
    "\n",
    "\n",
    "# ---- TRADES DATE ----\n",
    "if \"date\" in trades.columns:\n",
    "    trades[\"date\"] = pd.to_datetime(trades[\"date\"], errors=\"coerce\")\n",
    "elif \"timestamp\" in trades.columns:\n",
    "    trades[\"date\"] = pd.to_datetime(trades[\"timestamp\"], unit=\"s\", errors=\"coerce\")\n",
    "else:\n",
    "    raise KeyError(\"Trades dataset needs date or timestamp column\")\n",
    "\n",
    "# Remove rows with invalid/out-of-bounds dates\n",
    "trades = trades[trades[\"date\"].notna()]\n",
    "trades = trades[(trades[\"date\"].dt.year >= 2000) & (trades[\"date\"].dt.year <= 2100)]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4. MERGE DATASETS (CORRECT WAY)\n",
    "# ==============================\n",
    "sentiment_clean = sentiment[[\"date\", \"Classification\"]].drop_duplicates()\n",
    "\n",
    "df = trades.merge(\n",
    "    sentiment_clean,\n",
    "    on=\"date\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\",\n",
    ")\n",
    "\n",
    "print(\"\\nMerged dataset shape:\", df.shape)\n",
    "print(df[[\"date\", \"Classification\"]].drop_duplicates().head())\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset=[\"Classification\"])\n",
    "\n",
    "print(\"\\nColumns available:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 5. FEATURE ENGINEERING\n",
    "# ==============================\n",
    "\n",
    "# Fix PnL column naming automatically\n",
    "for col in df.columns:\n",
    "    if col.lower().replace(\" \", \"\") == \"closedpnl\":\n",
    "        df.rename(columns={col: \"closedPnL\"}, inplace=True)\n",
    "\n",
    "# Standardize size column\n",
    "for col in df.columns:\n",
    "    if \"size\" in col.lower() and \"tokens\" in col.lower():\n",
    "        df.rename(columns={col: \"size\"}, inplace=True)\n",
    "        break\n",
    "\n",
    "# Create leverage column if it doesn't exist\n",
    "if \"leverage\" not in df.columns:\n",
    "    df[\"leverage\"] = 1.0  # Default leverage value\n",
    "\n",
    "# Win flag\n",
    "df[\"win\"] = df[\"closedPnL\"] > 0\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 6. DAILY TRADER METRICS\n",
    "# ==============================\n",
    "daily = (\n",
    "    df.groupby([\"account\", \"date\", \"Classification\"])\n",
    "    .agg(\n",
    "        daily_PnL=(\"closedPnL\", \"sum\"),\n",
    "        num_trades=(\"closedPnL\", \"count\"),\n",
    "        total_size=(\"size\", \"sum\"),\n",
    "        avg_size=(\"size\", \"mean\"),\n",
    "        avg_leverage=(\"leverage\", \"mean\"),\n",
    "        long_trades=(\"side\", lambda x: (x == \"buy\").sum()),\n",
    "        short_trades=(\"side\", lambda x: (x == \"sell\").sum()),\n",
    "        win_days=(\"win\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "daily[\"long_ratio\"] = daily[\"long_trades\"] / daily[\"short_trades\"].replace(0, 1)\n",
    "\n",
    "print(\"\\nDaily metrics:\")\n",
    "print(daily.head())\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 7. ACCOUNT LEVEL STATS\n",
    "# ==============================\n",
    "account_stats = (\n",
    "    daily.groupby(\"account\")\n",
    "    .agg(\n",
    "        total_PnL=(\"daily_PnL\", \"sum\"),\n",
    "        avg_daily_PnL=(\"daily_PnL\", \"mean\"),\n",
    "        total_trades=(\"num_trades\", \"sum\"),\n",
    "        avg_daily_trades=(\"num_trades\", \"mean\"),\n",
    "        avg_leverage=(\"avg_leverage\", \"mean\"),\n",
    "        win_rate=(\"win_days\", \"mean\"),\n",
    "        n_days=(\"daily_PnL\", \"count\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Segmentation\n",
    "th_lvg = account_stats[\"avg_leverage\"].median()\n",
    "account_stats[\"leverage_category\"] = np.where(\n",
    "    account_stats[\"avg_leverage\"] > th_lvg,\n",
    "    \"High leverage\",\n",
    "    \"Low leverage\",\n",
    ")\n",
    "\n",
    "th_freq = account_stats[\"avg_daily_trades\"].median()\n",
    "account_stats[\"trading_frequency\"] = np.where(\n",
    "    account_stats[\"avg_daily_trades\"] > th_freq,\n",
    "    \"Frequent\",\n",
    "    \"Infrequent\",\n",
    ")\n",
    "\n",
    "account_stats[\"consistency\"] = np.where(\n",
    "    account_stats[\"win_rate\"] > 0.6,\n",
    "    \"Consistent\",\n",
    "    \"Inconsistent\",\n",
    ")\n",
    "\n",
    "daily = daily.merge(\n",
    "    account_stats[\n",
    "        [\"account\", \"leverage_category\", \"trading_frequency\", \"consistency\"]\n",
    "    ],\n",
    "    on=\"account\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 8. PERFORMANCE BY SENTIMENT\n",
    "# ==============================\n",
    "perf_by_sentiment = (\n",
    "    daily.groupby(\"Classification\")\n",
    "    .agg(\n",
    "        avg_daily_PnL=(\"daily_PnL\", \"mean\"),\n",
    "        median_daily_PnL=(\"daily_PnL\", \"median\"),\n",
    "        std_daily_PnL=(\"daily_PnL\", \"std\"),\n",
    "        win_rate=(\"daily_PnL\", lambda x: (x > 0).mean()),\n",
    "        avg_trades_per_day=(\"num_trades\", \"mean\"),\n",
    "        avg_leverage=(\"avg_leverage\", \"mean\"),\n",
    "    )\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "print(\"\\nPerformance by sentiment:\")\n",
    "print(perf_by_sentiment)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 9. VISUALIZATIONS\n",
    "# ==============================\n",
    "sns.boxplot(data=daily, x=\"Classification\", y=\"daily_PnL\")\n",
    "plt.title(\"Daily PnL by Fear vs Greed\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(\n",
    "    data=daily,\n",
    "    x=\"date\",\n",
    "    y=\"num_trades\",\n",
    "    hue=\"Classification\",\n",
    "    estimator=\"mean\",\n",
    "    errorbar=None,\n",
    ")\n",
    "plt.title(\"Avg trades per day by sentiment\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=daily, x=\"Classification\", y=\"avg_leverage\")\n",
    "plt.title(\"Avg leverage by sentiment\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 10. MACHINE LEARNING MODEL\n",
    "# ==============================\n",
    "daily = daily.sort_values([\"account\", \"date\"])\n",
    "\n",
    "daily[\"lag_PnL_1\"] = daily.groupby(\"account\")[\"daily_PnL\"].shift(1)\n",
    "daily[\"lag_trades_1\"] = daily.groupby(\"account\")[\"num_trades\"].shift(1)\n",
    "\n",
    "bins = [-np.inf, -1, 1, np.inf]\n",
    "labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "\n",
    "daily[\"next_PnL_bucket\"] = pd.cut(\n",
    "    daily.groupby(\"account\")[\"daily_PnL\"].shift(-1),\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    ")\n",
    "\n",
    "features = [\n",
    "    \"Classification\",\n",
    "    \"lag_PnL_1\",\n",
    "    \"lag_trades_1\",\n",
    "    \"avg_leverage\",\n",
    "    \"leverage_category\",\n",
    "    \"consistency\",\n",
    "]\n",
    "\n",
    "X = daily[features].dropna(subset=[\"lag_PnL_1\", \"next_PnL_bucket\"]).copy()\n",
    "y = daily.loc[X.index, \"next_PnL_bucket\"]\n",
    "\n",
    "X = pd.get_dummies(\n",
    "    X,\n",
    "    columns=[\"Classification\", \"leverage_category\", \"consistency\"],\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    min_samples_leaf=5,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nTrain Score:\", model.score(X_train, y_train))\n",
    "print(\"Test Score:\", model.score(X_test, y_test))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
